{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import enum\n",
    "\n",
    "from spear.labeling import labeling_function, LFSet, ABSTAIN, preprocessor\n",
    "\n",
    "from examples.TREC.preprocessor import convert_to_lower\n",
    "\n",
    "class ClassLabels(enum.Enum):\n",
    "    DESC     = 0\n",
    "    ENTY          = 1\n",
    "    HUM           = 2\n",
    "    ABBR    = 3\n",
    "    LOC       = 4\n",
    "    NUM         = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENTITY\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'ENTITY'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-8a179591465f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mrules\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_rules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-8a179591465f>\u001b[0m in \u001b[0;36mload_rules\u001b[0;34m(file_name)\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mlist_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_in\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClassLabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist_in\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist_in\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mrule_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"rule\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/enum.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(cls, name)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_member_map_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'ENTITY'"
     ]
    }
   ],
   "source": [
    "def load_rules(file_name='rules.txt'):\n",
    "    rules = LFSet(\"TREC_LFS\")\n",
    "    \n",
    "    with open(file_name, 'r', encoding='latin1') as f:\n",
    "        i = 0\n",
    "        for line in f:\n",
    "            list_in = line.strip().split(\"\\t\")\n",
    "            print(list_in)\n",
    "            label = ClassLabels[list_in[0]]\n",
    "            pattern = list_in[1]\n",
    "            rule_name = \"rule\"+str(i)\n",
    "            \n",
    "            @labeling_function(name=rule_name,resources=dict(pattern=pattern),pre=[convert_to_lower],label=label)\n",
    "            def f(x,**kwargs):\n",
    "                result = re.findall(kwargs[\"pattern\"], x)\n",
    "                if result:\n",
    "                    return label\n",
    "                else:\n",
    "                    return ABSTAIN\n",
    "\n",
    "            rules.add_lf(f)\n",
    "            i = i+1\n",
    "    return rules\n",
    "\n",
    "rules = load_rules()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_DICT = {\"DESCRIPTION\": 0, \"ENTITY\": 1, \"HUMAN\": 2, \"ABBREVIATION\": 3, \"LOCATION\": 4, \"NUMERIC\": 5}\n",
    "\n",
    "def load_data(mode):\n",
    "    label_map = {\"DESC\": \"0\", \"ENTY\": \"1\", \"HUM\": \"2\", \"ABBR\": \"3\", \"LOC\": \"4\",\n",
    "           \"NUM\": \"5\"}\n",
    "    data = []\n",
    "\n",
    "    with open(mode + '.txt', 'r', encoding='latin1') as f:\n",
    "        for line in f:\n",
    "            label = LABEL_DICT[label_map[line.split()[0].split(\":\")[0]]]\n",
    "            if mode == \"test\":\n",
    "                sentence = (\" \".join(line.split()[1:]))\n",
    "            else:\n",
    "                sentence = (\" \".join(line.split(\":\")[1:])).lower().strip()\n",
    "            data.append((sentence, label))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spear.labeling import preprocessor\n",
    "\n",
    "@preprocessor()\n",
    "def convert_to_lower(x):\n",
    "    return x.lower().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spear.labeling import PreLabels\n",
    "from notebooks.TREC.utils import load_data_to_numpy\n",
    "\n",
    "X_V, X_feats_V, Y_V = load_data_to_numpy(file_name='valid.txt')\n",
    "X_T, X_feats_T, Y_T = load_data_to_numpy(file_name='test.txt')\n",
    "X, X_feats, Y = load_data_to_numpy(file_name='train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_L, X_feats_L, Y_L, X_U, X_feats_U, Y_U = X[:100] , X_feats[:100], Y[:100], X[100:], X_feats[100:], Y[100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100,), (5352,), (500,), (500,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_L.shape, X_U.shape, X_V.shape, X_T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, X_feats, Y = load_data_to_numpy()\n",
    "# Y = np.array([ClassLabels[x].value for x in Y])\n",
    "\n",
    "# trec_noisy_labels = PreLabels(name=\"trec\",\n",
    "#                                data=X,\n",
    "#                                gold_labels=Y,\n",
    "#                                data_feats=X_feats,\n",
    "#                                rules=rules,\n",
    "#                                labels_enum=ClassLabels,\n",
    "#                                num_classes=6)\n",
    "# L,S = trec_noisy_labels.get_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from helper.utils import load_data_to_numpy, get_various_data\n",
    "\n",
    "# X_V = \n",
    "\n",
    "# X, X_feats, Y = load_data_to_numpy()\n",
    "\n",
    "# validation_size = 152\n",
    "# test_size = 500\n",
    "# L_size = 100\n",
    "# U_size = 4700\n",
    "# n_lfs = len(rules.get_lfs())\n",
    "\n",
    "# X_V, Y_V, X_feats_V,_, X_T, Y_T, X_feats_T,_, X_L, Y_L, X_feats_L,_, X_U, X_feats_U,_ = get_various_data(X, Y,\\\n",
    "#     X_feats, n_lfs, validation_size, test_size, L_size, U_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_json = 'data_pipeline/trec_json.json'\n",
    "V_path_pkl = 'data_pipeline/trec_pickle_V.pkl' #validation data - have true labels\n",
    "T_path_pkl = 'data_pipeline/trec_pickle_T.pkl' #test data - have true labels\n",
    "L_path_pkl = 'data_pipeline/trec_pickle_L.pkl' #Labeled data - have true labels\n",
    "U_path_pkl = 'data_pipeline/trec_pickle_U.pkl' #unlabelled data - don't have true labels\n",
    "\n",
    "log_path_cage_1 = 'log/trec_cage_log_1.txt' #cage is an algorithm, can be found below\n",
    "log_path_jl_1 = 'log/trec_jl_log_1.txt' #jl is an algorithm, can be found below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 1622.76it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 2203.44it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 1643.51it/s]\n",
      "100%|██████████| 5352/5352 [00:03<00:00, 1739.91it/s]\n"
     ]
    }
   ],
   "source": [
    "from spear.labeling import PreLabels\n",
    "\n",
    "trec_noisy_labels = PreLabels(name=\"trec\",\n",
    "                               data=X_V,\n",
    "                               gold_labels=Y_V,\n",
    "                               data_feats=X_feats_V,\n",
    "                               rules=rules,\n",
    "                               labels_enum=ClassLabels,\n",
    "                               num_classes=6)\n",
    "trec_noisy_labels.generate_pickle(V_path_pkl)\n",
    "trec_noisy_labels.generate_json(path_json) #generating json files once is enough\n",
    "\n",
    "trec_noisy_labels = PreLabels(name=\"trec\",\n",
    "                               data=X_T,\n",
    "                               gold_labels=Y_T,\n",
    "                               data_feats=X_feats_T,\n",
    "                               rules=rules,\n",
    "                               labels_enum=ClassLabels,\n",
    "                               num_classes=6)\n",
    "trec_noisy_labels.generate_pickle(T_path_pkl)\n",
    "\n",
    "trec_noisy_labels = PreLabels(name=\"trec\",\n",
    "                               data=X_L,\n",
    "                               gold_labels=Y_L,\n",
    "                               data_feats=X_feats_L,\n",
    "                               rules=rules,\n",
    "                               labels_enum=ClassLabels,\n",
    "                               num_classes=6)\n",
    "trec_noisy_labels.generate_pickle(L_path_pkl)\n",
    "\n",
    "trec_noisy_labels = PreLabels(name=\"trec\",\n",
    "                               data=X_U,\n",
    "                               rules=rules,\n",
    "                               data_feats=X_feats_U,\n",
    "                               labels_enum=ClassLabels,\n",
    "                               num_classes=6)\n",
    "trec_noisy_labels.generate_pickle(U_path_pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of elements in data list:  10\n",
      "Shape of feature matrix:  (5352, 1024)\n",
      "Shape of labels matrix:  (5352, 68)\n",
      "Shape of continuous scores matrix :  (5352, 68)\n",
      "Total number of classes:  6\n",
      "Classes dictionary in json file(modified to have integer keys):  {0: 'DESCRIPTION', 1: 'ENTITY', 2: 'HUMAN', 3: 'ABBREVIATION', 4: 'LOCATION', 5: 'NUMERIC'}\n"
     ]
    }
   ],
   "source": [
    "from spear.utils import get_data, get_classes\n",
    "\n",
    "data_U = get_data(path = U_path_pkl, check_shapes=True)\n",
    "#check_shapes being True(above), asserts for relative shapes of arrays in pickle file\n",
    "print(\"Number of elements in data list: \", len(data_U))\n",
    "print(\"Shape of feature matrix: \", data_U[0].shape)\n",
    "print(\"Shape of labels matrix: \", data_U[1].shape)\n",
    "print(\"Shape of continuous scores matrix : \", data_U[6].shape)\n",
    "print(\"Total number of classes: \", data_U[9])\n",
    "\n",
    "classes = get_classes(path = path_json)\n",
    "print(\"Classes dictionary in json file(modified to have integer keys): \", classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from spear.JL import JL\n",
    "\n",
    "# n_features = 1024\n",
    "# n_hidden = 512\n",
    "# feature_model = 'lr'\n",
    "\n",
    "# jl = JL(path_json = path_json, n_lfs = n_lfs, n_features = n_features, n_hidden = n_hidden, \\\n",
    "#         feature_model = feature_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/numba/np/ufunc/parallel.py:355: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9002. The TBB threading layer is disabled.\n",
      "  warnings.warn(problem)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'DESCRIPTION'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-25aaf389506d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mpath_T\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT_path_pkl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_fm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr_fm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_gm\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mlr_gm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_accuracy_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_accuracy_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_log\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_path_jl_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_gm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     100, start_len = 7,stop_len = 10, is_qt = True, is_qc = True, qt = 0.9, qc = 0.85, metric_avg = 'macro')\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs_fm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/spear/spear/JL/core.py\u001b[0m in \u001b[0;36mfit_and_predict_proba\u001b[0;34m(self, path_L, path_U, path_V, path_T, loss_func_mask, batch_size, lr_fm, lr_gm, use_accuracy_score, path_log, return_gm, n_epochs, start_len, stop_len, is_qt, is_qc, qt, qc, metric_avg)\u001b[0m\n\u001b[1;32m    200\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0mstart_len_\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mn_epochs_\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mstop_len\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mn_epochs_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m                 \u001b[0mdata_L\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_L\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m                 \u001b[0mdata_U\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_U\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m                 \u001b[0mdata_V\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_V\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/spear/spear/utils/data_editor.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(path, check_shapes, class_map)\u001b[0m\n\u001b[1;32m    106\u001b[0m                         \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m                         \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'DESCRIPTION'"
     ]
    }
   ],
   "source": [
    "from spear.JL import JL\n",
    "loss_func_mask = [1,1,1,1,1,1,1]\n",
    "'''\n",
    "One can keep 0s in places where he don't want the specific loss function to be part\n",
    "the final loss function used in training. Refer documentation(spear.JL.core.JL) to understand\n",
    "the which index of loss_func_mask refers to what loss function.\n",
    "Note: the loss_func_mask may not be the optimal mask for sms dataset.\n",
    "'''\n",
    "batch_size = 150\n",
    "lr_fm = 0.0005\n",
    "lr_gm = 0.01\n",
    "use_accuracy_score = False\n",
    "feature_model = 'nn'\n",
    "n_features = 1024\n",
    "n_hidden = 512\n",
    "n_lfs = len(rules.get_lfs())\n",
    "jl = JL(path_json = path_json, n_lfs = n_lfs, n_features = n_features, n_hidden = n_hidden, \\\n",
    "        feature_model = feature_model)\n",
    "\n",
    "probs_fm, probs_gm = jl.fit_and_predict_proba(path_L = L_path_pkl, path_U = U_path_pkl, path_V = V_path_pkl, \\\n",
    "        path_T = T_path_pkl, loss_func_mask = loss_func_mask, batch_size = batch_size, lr_fm = lr_fm, lr_gm = \\\n",
    "    lr_gm, use_accuracy_score = use_accuracy_score, path_log = log_path_jl_1, return_gm = True, n_epochs = \\\n",
    "    100, start_len = 7,stop_len = 10, is_qt = True, is_qc = True, qt = 0.9, qc = 0.85, metric_avg = 'macro')\n",
    "\n",
    "labels = np.argmax(probs_fm, 1)\n",
    "print(\"probs_fm shape: \", probs_fm.shape)\n",
    "print(\"probs_gm shape: \", probs_gm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
